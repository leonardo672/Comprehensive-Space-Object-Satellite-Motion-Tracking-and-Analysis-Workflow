{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a785dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cd yolov5 && python train.py --img 320 --batch 9 --epochs 250 --data dataset_2_P4_and_TB2.yml --weights yolov5s.pt --workers 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdc6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Last for save detected satellite images + send satellite_information Like Name,X,Y,Z Coordinates to database Excel  \n",
    "# 1. Локализация объекта (спутника) с использованием YOLOv5 на видеокадрах.\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='C:/Users/L/yolov5/runs/Satallite/exp/weights/last.pt', force_reload=True)\n",
    "\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)     \n",
    "\n",
    "def detect_and_store_information(input_path, new_width, new_height, output_folder, excel_filename, record_video=False):\n",
    "\n",
    "    detect_images_folder = os.path.join(output_folder, 'Detected_images')\n",
    "    video_folder = os.path.join(output_folder, 'Video')\n",
    "\n",
    "    create_directory(detect_images_folder)  # Create folder to store detected satellite images\n",
    "    create_directory(video_folder)  # Create folder to store recorded video\n",
    "\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    satellite_count = 0\n",
    "\n",
    "    # Lists to store satellite information\n",
    "    satellite_names, x_coords, y_coords, z_coords = [], [], [], []\n",
    "\n",
    "    # Define the codec and create VideoWriter object if recording is enabled\n",
    "    if record_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(os.path.join(video_folder, 'output.avi'), fourcc, 20.0, (new_width, new_height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (new_width, new_height))\n",
    "        results = model(frame)\n",
    "        detected_satellites = results.xyxy[0]\n",
    "\n",
    "        for sat_idx, sat in enumerate(detected_satellites):\n",
    "            x1, y1, x2, y2, confidence, class_id = sat\n",
    "            satellite_name = f\"Satellite_{satellite_count}_{sat_idx}\"\n",
    "            x_coord = int((x1 + x2) / 2)\n",
    "            y_coord = int((y1 + y2) / 2)\n",
    "            z_coord = int((x_coord + y_coord) * 1.5)  # Calculating z as (x + y) * 1.5    \n",
    "            \n",
    "            # Crop the detected satellite from the frame\n",
    "            cropped_satellite = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "          \n",
    "            # Save the cropped satellite image to the detect_images folder\n",
    "            cv2.imwrite(os.path.join(detect_images_folder, f\"{satellite_name}.jpg\"), cropped_satellite)\n",
    "            \n",
    "            # Append satellite information to lists\n",
    "            satellite_names.append(satellite_name)\n",
    "            x_coords.append(x_coord)\n",
    "            y_coords.append(y_coord)\n",
    "            z_coords.append(z_coord)\n",
    "\n",
    "            satellite_count += 1\n",
    "\n",
    "        cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "        \n",
    "        # Write the frame into the output video if recording is enabled\n",
    "        if record_video:\n",
    "            out.write(frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    data = {\n",
    "        'Satellite Name': satellite_names,\n",
    "        'X-coordinate': x_coords,\n",
    "        'Y-coordinate': y_coords,\n",
    "        'Z-coordinate': z_coords,  # Include Z-coordinate in the DataFrame\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to an Excel file\n",
    "    df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if record_video:\n",
    "        out.release()\n",
    "\n",
    "# Example usage\n",
    "input_video_path = 'D:/Python_Project_Tracking/Untitled_Project_V1.mp4'\n",
    "new_width = 640\n",
    "new_height = 480\n",
    "output_folder = 'D:/Python_Project_Tracking'  # Base folder to contain detect_images and video folders\n",
    "excel_filename = 'D:/Python_Project_Tracking/satellite_information.xlsx'\n",
    "\n",
    "detect_and_store_information(input_video_path, new_width, new_height, output_folder, excel_filename, record_video=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe68b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last - visualize the movement of our object and store every step of the movment in our database(local folder) like and image\n",
    " # 2. 3D визуализация движения объекта (спутника) и близости датчиков.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib.widgets import Button\n",
    "import os\n",
    "\n",
    "# Load data from satellite_information.xlsx\n",
    "data = pd.read_excel('D://Python_Project_Tracking//position_data.xlsx')\n",
    "output_folder = 'D://Python_Project_Tracking//Object_Movement_1'\n",
    "\n",
    "def save_step_image(step_num, fig):\n",
    "    folder_path = output_folder\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    plt.savefig(os.path.join(folder_path, f'step_{step_num:03d}.png'))\n",
    "\n",
    "# Extract X, Y, and Z coordinates from the loaded data\n",
    "object_positions_x = data['X'].tolist()\n",
    "object_positions_y = data['Y'].tolist()\n",
    "object_positions_z = data['Z'].tolist()\n",
    "\n",
    "# Define sensor positions within the range of -100 to 1000 for x, y, and z axes\n",
    "sensor_positions = [\n",
    "    (-10000, -10000, 0),  # Sensor 1 position (x, y, z)\n",
    "    (13000, -13000, 0),  # Sensor 2 position (x, y, z)\n",
    "    (0, 14000, 0),       # Sensor 3 position (x, y, z)\n",
    "]\n",
    "\n",
    "# Create a 3D figure\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Adding a 3D subplot\n",
    "\n",
    "# Set limits for x, y, and z axes\n",
    "ax.set_xlim(-15000, 15000)\n",
    "ax.set_ylim(-15000, 15000)\n",
    "ax.set_zlim(-15000, 15000)\n",
    "\n",
    "# Plot sensor positions in 3D\n",
    "for sensor_pos in sensor_positions:\n",
    "    ax.scatter(sensor_pos[0], sensor_pos[1], sensor_pos[2], color='red', marker='^', label='Sensor')\n",
    "\n",
    "# Label sensors in 3D\n",
    "sensor_labels = ['Sensor 1', 'Sensor 2', 'Sensor 3']\n",
    "for i, sensor_pos in enumerate(sensor_positions):\n",
    "    ax.text(sensor_pos[0], sensor_pos[1], sensor_pos[2], sensor_labels[i], color='black', fontsize=10)\n",
    "\n",
    "# Initialize variables for simulation control\n",
    "paused = False\n",
    "current_step = 0\n",
    "sensor_lines = []  # Store sensor lines\n",
    "exit_simulation = False  # Define the exit_simulation flag\n",
    "\n",
    "def toggle_pause(event):\n",
    "    global paused\n",
    "    paused = not paused\n",
    "\n",
    "    if paused:\n",
    "        button.label.set_text('Resume')\n",
    "    else:\n",
    "        button.label.set_text('Pause')\n",
    "        simulate(current_step)  # Resume simulation from the current step\n",
    "\n",
    "# Pause/Resume button\n",
    "button_ax = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "button = Button(button_ax, 'Pause')\n",
    "button.on_clicked(toggle_pause)\n",
    "\n",
    "def on_key(event):\n",
    "    global paused, exit_simulation\n",
    "    if event.key == 'q':\n",
    "        exit_simulation = True\n",
    "\n",
    "fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "def simulate(start_step=0):\n",
    "    global current_step, paused, sensor_lines, exit_simulation\n",
    "\n",
    "    for i in range(start_step, len(object_positions_x)):\n",
    "        if exit_simulation:\n",
    "            break\n",
    "\n",
    "        if not paused:\n",
    "            current_step = i\n",
    "\n",
    "            scaling_factor = 3\n",
    "            object_x = object_positions_x[i] * scaling_factor\n",
    "            object_y = object_positions_y[i] * scaling_factor\n",
    "            object_z = object_positions_z[i] * scaling_factor  # Fetch the Z-coordinate\n",
    "\n",
    "            ax.scatter(object_x, object_y, object_z, color='blue', marker='o', label='Object Position')\n",
    "\n",
    "            if i > 0:  # Connect consecutive object positions with a line\n",
    "                ax.plot([object_positions_x[i-1]*scaling_factor, object_x],\n",
    "                        [object_positions_y[i-1]*scaling_factor, object_y],\n",
    "                        [object_positions_z[i-1]*scaling_factor, object_z],\n",
    "                        color='green', linestyle='-', label='_nolegend_')\n",
    "\n",
    "            # Remove previous sensor lines\n",
    "            for line in sensor_lines:\n",
    "                line.remove()\n",
    "\n",
    "            sensor_lines = []  # Clear sensor lines list for new lines\n",
    "\n",
    "            # Draw sensor lines\n",
    "            for sensor_pos in sensor_positions:\n",
    "                sensor_line = ax.plot([object_x, sensor_pos[0]],\n",
    "                                      [object_y, sensor_pos[1]],\n",
    "                                      [object_z, sensor_pos[2]],\n",
    "                                      linestyle='--', color='green', alpha=0.5, label='_nolegend_')\n",
    "                sensor_lines.append(sensor_line[0])\n",
    "\n",
    "            plt.title(f'Object Movement: Step {i+1}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            save_step_image(i, fig)\n",
    "            plt.pause(0.1)\n",
    "\n",
    "    if not exit_simulation:\n",
    "        plt.close(fig)  # Close the figure if simulation completes without 'q' key press\n",
    "\n",
    "# Start simulation\n",
    "simulate()\n",
    "\n",
    "# Check if the simulation is paused before displaying the plot\n",
    "if paused:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.show(block=False)  # Set block=False to keep the figure open without blocking code execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fe7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images (steps of the movment pf our object) to video \n",
    "# 3. Создание видео движения объекта (спутника) из 3D снимков.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the directory containing images\n",
    "images_folder = 'D://Python_Project_Tracking//Object_Movement_1'  # Path to your image folder\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = sorted([os.path.join(images_folder, f) for f in os.listdir(images_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.gif'))])\n",
    "\n",
    "# Get the first image to extract dimensions\n",
    "first_image = cv2.imread(image_files[0])\n",
    "height, width, layers = first_image.shape\n",
    "\n",
    "# Video filename and codec\n",
    "video_filename = 'D://Python_Project_Tracking//Object_Movement_1.mp4'  # Path for the output video\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "\n",
    "# Create VideoWriter object\n",
    "video = cv2.VideoWriter(video_filename, codec, 24, (width, height))\n",
    "\n",
    "# Write images to video\n",
    "for image in image_files:\n",
    "    img = cv2.imread(image)\n",
    "    video.write(img)\n",
    "\n",
    "# Release video object\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c1bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Реально-временный пространственный анализ динамики спутника-наблюдателя в 3D пространстве.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate altitude from three angle measurements\n",
    "def calculate_altitude(angle_observer_a, angle_observer_b, angle_observer_c, \n",
    "                       distance_between_observers_1, distance_between_observers_2, distance_between_observers_3):\n",
    "    angle_observer_a_rad = np.deg2rad(angle_observer_a)\n",
    "    angle_observer_b_rad = np.deg2rad(angle_observer_b)\n",
    "    angle_observer_c_rad = np.deg2rad(angle_observer_c)\n",
    "\n",
    "    altitude_1 = distance_between_observers_1 * np.tan(angle_observer_a_rad) * np.tan(angle_observer_b_rad) / (\n",
    "            np.tan(angle_observer_a_rad) - np.tan(angle_observer_b_rad))\n",
    "\n",
    "    altitude_2 = distance_between_observers_2 * np.tan(angle_observer_b_rad) * np.tan(angle_observer_c_rad) / (\n",
    "            np.tan(angle_observer_b_rad) - np.tan(angle_observer_c_rad))\n",
    "\n",
    "    altitude_3 = distance_between_observers_3 * np.tan(angle_observer_a_rad) * np.tan(angle_observer_c_rad) / (\n",
    "            np.tan(angle_observer_a_rad) - np.tan(angle_observer_c_rad))\n",
    "\n",
    "    return altitude_1, altitude_2, altitude_3\n",
    "\n",
    "\n",
    "def get_distances(x1, y1, z1, x2, y2, z2, x3, y3, z3):\n",
    "    distance_1_2 = np.sqrt((x1 - x2) ** 2 + (y1 - y2) ** 2 + (z1 - z2) ** 2)\n",
    "    distance_2_3 = np.sqrt((x2 - x3) ** 2 + (y2 - y3) ** 2 + (z2 - z3) ** 2)\n",
    "    distance_1_3 = np.sqrt((x1 - x3) ** 2 + (y1 - y3) ** 2 + (z1 - z3) ** 2)\n",
    "\n",
    "    return distance_1_2, distance_2_3, distance_1_3\n",
    "\n",
    "def get_angle_measurements_and_distance(x_coord, y_coord, z_coord, x1, y1, z1, x2, y2, z2, x3, y3, z3):\n",
    "    distance_1 = np.sqrt((x_coord - x1) ** 2 + (y_coord - y1) ** 2 + (z_coord - z1) ** 2)\n",
    "    distance_2 = np.sqrt((x_coord - x2) ** 2 + (y_coord - y2) ** 2 + (z_coord - z2) ** 2)\n",
    "    distance_3 = np.sqrt((x_coord - x3) ** 2 + (y_coord - y3) ** 2 + (z_coord - z3) ** 2)\n",
    "\n",
    "    angle_observer_a = np.arctan2(z_coord - z1, distance_1)\n",
    "    angle_observer_b = np.arctan2(z_coord - z2, distance_2)\n",
    "    angle_observer_c = np.arctan2(z_coord - z3, distance_3)\n",
    "\n",
    "    return angle_observer_a, angle_observer_b, angle_observer_c, distance_1, distance_2, distance_3\n",
    "\n",
    "def main():\n",
    "    x1, y1, z1 = 100, 200, 50\n",
    "    x2, y2, z2 = 300, 500, 800\n",
    "    x3, y3, z3 = 800, 700, 900\n",
    "\n",
    "    excel_file_path = \"D://Python_Project_Tracking//satellite_information.xlsx\"\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        x_coord, y_coord, z_coord = df.iloc[i, 1:4].tolist()\n",
    "\n",
    "        distance_1_2, distance_2_3, distance_1_3 = get_distances(x1, y1, z1, x2, y2, z2, x3, y3, z3)\n",
    "\n",
    "        angle_observer_a, angle_observer_b, angle_observer_c, distance_1, distance_2, distance_3 = \\\n",
    "            get_angle_measurements_and_distance(x_coord, y_coord, z_coord, x1, y1, z1, x2, y2, z2, x3, y3, z3)\n",
    "\n",
    "        altitude_1, altitude_2, altitude_3 = calculate_altitude(\n",
    "            np.degrees(angle_observer_a), np.degrees(angle_observer_b), np.degrees(angle_observer_c),\n",
    "            distance_1_2, distance_2_3, distance_1_3\n",
    "        )\n",
    "\n",
    "        all_data.append([x_coord, y_coord, z_coord, x1, y1, z1, x2, y2, z2, x3, y3, z3,\n",
    "                         distance_1_2, distance_2_3, distance_1_3,\n",
    "                         np.degrees(angle_observer_a), np.degrees(angle_observer_b), np.degrees(angle_observer_c),\n",
    "                         altitude_1, altitude_2, altitude_3, distance_1, distance_2, distance_3])\n",
    "\n",
    "    columns = ['X_Object', 'Y_Object', 'Z_Object', 'X_Observer1', 'Y_Observer1', 'Z_Observer1',\n",
    "               'X_Observer2', 'Y_Observer2', 'Z_Observer2', 'X_Observer3', 'Y_Observer3', 'Z_Observer3',\n",
    "               'Distance_Observer1_2', 'Distance_Observer2_3', 'Distance_Observer1_3',\n",
    "               'Angle_Observer1', 'Angle_Observer2', 'Angle_Observer3',\n",
    "               'Altitude_Observer1', 'Altitude_Observer2', 'Altitude_Observer3',\n",
    "               'Distance_Object_Observer1', 'Distance_Object_Observer2', 'Distance_Object_Observer3']\n",
    "\n",
    "    result_df = pd.DataFrame(all_data, columns=columns)\n",
    "\n",
    "    result_df.to_excel(\"D://Python_Project_Tracking//Time_Spatial_Analysis_Results.xlsx\", index=False)\n",
    "    print(\"Data sending operation completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e754c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Last - visualize all changes and store it in separate folders in the local system\n",
    "# 5. Динамическая визуализация координат для объекта (спутника) и наблюдателей.\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to create directories if they don't exist\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Directory paths for saving plots\n",
    "directories = [\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Object\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Observer1\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Observer2\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Observer3\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Distances_Observers\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Angles\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Distances_Object_Observer\",\n",
    "    \"D://Python_Project_Tracking//Coordinate_Plots_Altitude_Observers\"\n",
    "]\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for directory in directories:\n",
    "    create_directory(directory)\n",
    "\n",
    "# Load the data from the result_coordinates.xlsx file\n",
    "file_path = \"D://Python_Project_Tracking//Time_Spatial_Analysis_Results.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Coordinates to plot\n",
    "object_coordinates = ['X_Object', 'Y_Object', 'Z_Object']\n",
    "observer1_coordinates = ['X_Observer1', 'Y_Observer1', 'Z_Observer1']\n",
    "observer2_coordinates = ['X_Observer2', 'Y_Observer2', 'Z_Observer2']\n",
    "observer3_coordinates = ['X_Observer3', 'Y_Observer3', 'Z_Observer3']\n",
    "distance_coordinates = ['Distance_Observer1_2', 'Distance_Observer2_3', 'Distance_Observer1_3']\n",
    "angle_coordinates = ['Angle_Observer1', 'Angle_Observer2', 'Angle_Observer3']\n",
    "observer_object_distance_coordinates = ['Distance_Object_Observer1', 'Distance_Object_Observer2', 'Distance_Object_Observer3']\n",
    "altitude_coordinates = ['Altitude_Observer1', 'Altitude_Observer2', 'Altitude_Observer3']\n",
    "\n",
    "# Function to plot and save coordinates\n",
    "def plot_coordinates(coordinates, directory, title_prefix):\n",
    "    for coord in coordinates:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(df.index, df[coord])\n",
    "        plt.title(f\"{title_prefix} - Change in {coord} over Time\")\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel(coord)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{directory}//{coord}_change.png\")  # Save each plot for the coordinates\n",
    "        plt.close()\n",
    "\n",
    "# Plot and save coordinates for each set of coordinates\n",
    "plot_coordinates(object_coordinates, directories[0], \"Object\")\n",
    "plot_coordinates(observer1_coordinates, directories[1], \"Observer 1\")\n",
    "plot_coordinates(observer2_coordinates, directories[2], \"Observer 2\")\n",
    "plot_coordinates(observer3_coordinates, directories[3], \"Observer 3\")\n",
    "plot_coordinates(distance_coordinates, directories[4], \"Distances_Observers\")\n",
    "plot_coordinates(angle_coordinates, directories[5], \"Angles\")\n",
    "plot_coordinates(observer_object_distance_coordinates, directories[6], \"Distances_Object_Observer\")\n",
    "plot_coordinates(altitude_coordinates, directories[7], \"Altitude_Observers\")\n",
    "\n",
    "print(\"All visualizations have been generated and stored successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Floating-point arithmetic in computers has limitations due to the way they represent and store real numbers. These limitations can lead to precision issues and rounding errors. Python, like many programming languages, uses floating-point representation to store decimal numbers. However, the internal representation of decimal numbers in computers is not exact and can lead to small discrepancies in calculations.\n",
    "\n",
    "For instance, calculations involving very small or very large numbers, repeated operations, or operations that involve irrational numbers can exhibit these differences. Additionally, mathematical operations might yield results slightly different from what we expect due to the limited precision of floating-point numbers.\n",
    "\n",
    "Python's floating-point arithmetic operates within these constraints, and while it provides high precision for most purposes, certain calculations might yield results that differ slightly from mathematical expectations. This behavior is common across programming languages and is inherent to the way computers handle floating-point numbers. Strategies like rounding or using higher precision arithmetic libraries can sometimes help mitigate these issues, but they might not eliminate them entirely.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33f00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangulation \n",
    "# 6. Триангуляция для определения позиции объекта (спутника).\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from the Excel file\n",
    "file_path = \"D://Python_Project_Tracking//Time_Spatial_Analysis_Results.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Coordinates and distances from the Excel columns\n",
    "observer_coordinates = [\n",
    "    ['X_Observer1', 'Y_Observer1', 'Z_Observer1'],\n",
    "    ['X_Observer2', 'Y_Observer2', 'Z_Observer2'],\n",
    "    ['X_Observer3', 'Y_Observer3', 'Z_Observer3']\n",
    "]\n",
    "distance_coordinates = ['Distance_Object_Observer1', 'Distance_Object_Observer2', 'Distance_Object_Observer3']\n",
    "angle_coordinates = ['Angle_Observer1', 'Angle_Observer2', 'Angle_Observer3']\n",
    "\n",
    "# Triangulation using distances and angles\n",
    "def triangulation(df, observer_coords, distance_coords, angle_coords):\n",
    "    # Collect observer coordinates, distances, and angles for each observer\n",
    "    observers = []\n",
    "    for i in range(3):\n",
    "        observer = df[observer_coords[i]].values\n",
    "        distance = df[distance_coords[i]].values\n",
    "        angle = np.radians(df[angle_coords[i]].values)\n",
    "        observers.append({'observer': observer, 'distance': distance, 'angle': angle})\n",
    "\n",
    "    # Perform triangulation\n",
    "    results = []\n",
    "    for i in range(len(df)):\n",
    "        A = np.vstack([\n",
    "            -np.cos(observers[0]['angle'][i]), -np.sin(observers[0]['angle'][i]), 1,\n",
    "            -np.cos(observers[1]['angle'][i]), -np.sin(observers[1]['angle'][i]), 1,\n",
    "            -np.cos(observers[2]['angle'][i]), -np.sin(observers[2]['angle'][i]), 1\n",
    "        ]).reshape((3, 3))\n",
    "\n",
    "        b = np.vstack([\n",
    "            -observers[0]['distance'][i] * np.cos(observers[0]['angle'][i]),\n",
    "            -observers[1]['distance'][i] * np.cos(observers[1]['angle'][i]),\n",
    "            -observers[2]['distance'][i] * np.cos(observers[2]['angle'][i])\n",
    "        ])\n",
    "\n",
    "        # Calculate triangulation coordinates\n",
    "        triangulation_coord = np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "        results.append(triangulation_coord.T)\n",
    "\n",
    "    return np.array(results)\n",
    "\n",
    "# Perform triangulation with distances and angles\n",
    "triangulation_result = triangulation(df, observer_coordinates, distance_coordinates, angle_coordinates)\n",
    "\n",
    "# Reshape the array to 2D for Excel compatibility\n",
    "reshaped_result = triangulation_result.reshape(triangulation_result.shape[0], -1)\n",
    "\n",
    "# Convert the reshaped array to a DataFrame\n",
    "result_df = pd.DataFrame(reshaped_result)\n",
    "\n",
    "# Add header for X, Y, Z as the first row\n",
    "result_df.columns = ['X', 'Y', 'Z']\n",
    "\n",
    "# Define the path for the new Excel file\n",
    "output_file_path = \"D://Python_Project_Tracking//triangulation_results.xlsx\"\n",
    "\n",
    "# Write the DataFrame to an Excel file with headers\n",
    "result_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Display a message when the saving is completed\n",
    "print(f\"Triangulation results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508983d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data from 'D://Python_Project_Tracking//triangulation_results.xlsx'\n",
    "data = pd.read_excel('D://Python_Project_Tracking//triangulation_results.xlsx')\n",
    "\n",
    "output_folder = 'D://Python_Project_Tracking//Positional_Lines'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to plot and save coordinates\n",
    "def plot_coordinates(coordinates, directory, title_prefix):\n",
    "    for coord in coordinates:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(len(data)), data[coord], marker='.')\n",
    "        plt.title(f\"{title_prefix} - Change in {coord} over Time\")\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel(coord)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{directory}//{coord}_change.png\")  # Save each plot for the coordinates\n",
    "        plt.close()\n",
    "\n",
    "# Plot and save coordinates for X, Y, and Z\n",
    "plot_coordinates(['X', 'Y', 'Z'], output_folder, \"Object\")'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fed2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Визуальный анализ траектории координат объекта (спутника) в 3D пространстве во времени на основе результатов триангуляции.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load data from 'D://Python_Project_Tracking//triangulation_results.xlsx'\n",
    "data = pd.read_excel('D://Python_Project_Tracking//position_data.xlsx')\n",
    "\n",
    "output_folder = 'D://Python_Project_Tracking//Positional_Lines_true'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to plot and save coordinates\n",
    "def plot_coordinates(coordinates, directory, title_prefix):\n",
    "    for coord in coordinates:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(range(len(data)), data[coord], marker='.')\n",
    "        plt.title(f\"{title_prefix} - Change in {coord} over Time\")\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel(coord)\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{directory}//{coord}_change.png\")  # Save each plot for the coordinates\n",
    "        plt.close()\n",
    "\n",
    "# Plot and save coordinates for X, Y, and Z\n",
    "plot_coordinates(['X', 'Y', 'Z'], output_folder, \"Object\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c93f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Triangulation results visualizations\n",
    "# 8. Динамическая 3D визуализация траектории объекта (спутника) и взаимодействия сенсоров после процесса триангуляции.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib.widgets import Button\n",
    "import os\n",
    "\n",
    "# Load data from satellite_information.xlsx\n",
    "data = pd.read_excel('D://Python_Project_Tracking//position_data.xlsx')\n",
    "output_folder = 'D://Python_Project_Tracking//Output_triangulation_results'\n",
    "\n",
    "def save_step_image(step_num, fig):\n",
    "    folder_path = output_folder\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    plt.savefig(os.path.join(folder_path, f'step_{step_num:03d}.png'))\n",
    "\n",
    "# Extract X, Y, and Z coordinates from the loaded data\n",
    "object_positions_x = data['X'].tolist()\n",
    "object_positions_y = data['Y'].tolist()\n",
    "object_positions_z = data['Z'].tolist()\n",
    "\n",
    "# Define sensor positions within the range of -100 to 1000 for x, y, and z axes\n",
    "sensor_positions = [\n",
    "    (-10000, -10000, 0),  # Sensor 1 position (x, y, z)\n",
    "    (13000, -13000, 0),  # Sensor 2 position (x, y, z)\n",
    "    (0, 14000, 0),       # Sensor 3 position (x, y, z)\n",
    "]\n",
    "\n",
    "# Create a 3D figure\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Adding a 3D subplot\n",
    "\n",
    "# Set limits for x, y, and z axes\n",
    "ax.set_xlim(-15000, 15000)\n",
    "ax.set_ylim(-15000, 15000)\n",
    "ax.set_zlim(-15000, 15000)\n",
    "\n",
    "# Plot sensor positions in 3D\n",
    "for sensor_pos in sensor_positions:\n",
    "    ax.scatter(sensor_pos[0], sensor_pos[1], sensor_pos[2], color='red', marker='^', label='Sensor')\n",
    "\n",
    "# Label sensors in 3D\n",
    "sensor_labels = ['Sensor 1', 'Sensor 2', 'Sensor 3']\n",
    "for i, sensor_pos in enumerate(sensor_positions):\n",
    "    ax.text(sensor_pos[0], sensor_pos[1], sensor_pos[2], sensor_labels[i], color='black', fontsize=10)\n",
    "\n",
    "# Initialize variables for simulation control\n",
    "paused = False\n",
    "current_step = 0\n",
    "sensor_lines = []  # Store sensor lines\n",
    "exit_simulation = False  # Define the exit_simulation flag\n",
    "\n",
    "def toggle_pause(event):\n",
    "    global paused\n",
    "    paused = not paused\n",
    "\n",
    "    if paused:\n",
    "        button.label.set_text('Resume')\n",
    "    else:\n",
    "        button.label.set_text('Pause')\n",
    "        simulate(current_step)  # Resume simulation from the current step\n",
    "\n",
    "# Pause/Resume button\n",
    "button_ax = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "button = Button(button_ax, 'Pause')\n",
    "button.on_clicked(toggle_pause)\n",
    "\n",
    "def on_key(event):\n",
    "    global paused, exit_simulation\n",
    "    if event.key == 'q':\n",
    "        exit_simulation = True\n",
    "\n",
    "fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "def simulate(start_step=0):\n",
    "    global current_step, paused, sensor_lines, exit_simulation\n",
    "\n",
    "    for i in range(start_step, len(object_positions_x)):\n",
    "        if exit_simulation:\n",
    "            break\n",
    "\n",
    "        if not paused:\n",
    "            current_step = i\n",
    "\n",
    "            scaling_factor = 3\n",
    "            object_x = object_positions_x[i] * scaling_factor\n",
    "            object_y = object_positions_y[i] * scaling_factor\n",
    "            object_z = object_positions_z[i] * scaling_factor  # Fetch the Z-coordinate\n",
    "\n",
    "            ax.scatter(object_x, object_y, object_z, color='blue', marker='o', label='Object Position')\n",
    "\n",
    "            if i > 0:  # Connect consecutive object positions with a line\n",
    "                ax.plot([object_positions_x[i-1]*scaling_factor, object_x],\n",
    "                        [object_positions_y[i-1]*scaling_factor, object_y],\n",
    "                        [object_positions_z[i-1]*scaling_factor, object_z],\n",
    "                        color='green', linestyle='-', label='_nolegend_')\n",
    "\n",
    "            # Remove previous sensor lines\n",
    "            for line in sensor_lines:\n",
    "                line.remove()\n",
    "\n",
    "            sensor_lines = []  # Clear sensor lines list for new lines\n",
    "\n",
    "            # Draw sensor lines\n",
    "            for sensor_pos in sensor_positions:\n",
    "                sensor_line = ax.plot([object_x, sensor_pos[0]],\n",
    "                                      [object_y, sensor_pos[1]],\n",
    "                                      [object_z, sensor_pos[2]],\n",
    "                                      linestyle='--', color='green', alpha=0.5, label='_nolegend_')\n",
    "                sensor_lines.append(sensor_line[0])\n",
    "\n",
    "            plt.title(f'Object Movement: Step {i+1}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            save_step_image(i, fig)\n",
    "            plt.pause(0.1)\n",
    "\n",
    "    if not exit_simulation:\n",
    "        plt.close(fig)  # Close the figure if simulation completes without 'q' key press\n",
    "\n",
    "# Start simulation\n",
    "simulate()\n",
    "\n",
    "# Check if the simulation is paused before displaying the plot\n",
    "if paused:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.show(block=False)  # Set block=False to keep the figure open without blocking code execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec785a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images (steps of the movment pf our object) to video \n",
    "# 9. Создание видео движения объекта (спутника) из 3D снимков.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the directory containing images\n",
    "images_folder = 'D://Python_Project_Tracking//Output'  # Path to your image folder\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = sorted([os.path.join(images_folder, f) for f in os.listdir(images_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.gif'))])\n",
    "\n",
    "# Get the first image to extract dimensions\n",
    "first_image = cv2.imread(image_files[0])\n",
    "height, width, layers = first_image.shape\n",
    "\n",
    "# Video filename and codec\n",
    "video_filename = 'D://Python_Project_Tracking//output_video.mp4'  # Path for the output video\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "\n",
    "# Create VideoWriter object\n",
    "video = cv2.VideoWriter(video_filename, codec, 24, (width, height))\n",
    "\n",
    "# Write images to video\n",
    "for image in image_files:\n",
    "    img = cv2.imread(image)\n",
    "    video.write(img)\n",
    "\n",
    "# Release video object\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Accuracy Validation: After performing triangulation, compare the calculated positions with the virtual locations \n",
    "obtained from video detection. You can create a comparison function to evaluate the alignment between\n",
    "the detected positions and expected positions based on observational data.\n",
    "This function might calculate differences or metrics to verify accuracy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b48b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Validatio\n",
    "# 10. Виртуальный оценщик точности координатной триангуляции.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load original coordinates from video detection\n",
    "original_df = pd.read_excel('D://Python_Project_Tracking//modified_coordinates_1.xlsx')\n",
    "\n",
    "# Load triangulation results\n",
    "triangulation_df = pd.read_excel(\"D://Python_Project_Tracking//modified_coordinates_2.xlsx\")\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows or handle the mismatch\n",
    "if original_df.shape[0] != triangulation_df.shape[0]:\n",
    "    print(\"Number of rows in the DataFrames do not match. Adjusting...\")\n",
    "\n",
    "    # Adjust the DataFrames to have the same number of rows\n",
    "    min_rows = min(original_df.shape[0], triangulation_df.shape[0])\n",
    "    original_df = original_df.iloc[:min_rows]\n",
    "    triangulation_df = triangulation_df.iloc[:min_rows]\n",
    "\n",
    "# Extract coordinates from DataFrames\n",
    "original_coords = original_df[['X', 'Y', 'Z']].values\n",
    "triangulation_coords = triangulation_df[['X', 'Y', 'Z']].values\n",
    "\n",
    "# Calculate differences or metrics to verify alignment\n",
    "differences = triangulation_coords - original_coords\n",
    "\n",
    "# Calculate metrics for accuracy validation\n",
    "mean_difference = differences.mean()\n",
    "rmse = ((differences ** 2).mean()) ** 0.5\n",
    "\n",
    "# Print or use the calculated metrics\n",
    "print(f\"Mean Difference: {mean_difference}\")\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Accuracy Validation\n",
    "# 11. Визуализация и проверка точности 3D координат.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load original coordinates from video detection\n",
    "original_df = pd.read_excel('D://Python_Project_Tracking//modified_coordinates_1.xlsx')\n",
    "\n",
    "# Load triangulation results\n",
    "triangulation_df = pd.read_excel(\"D://Python_Project_Tracking//modified_coordinates_2.xlsx\")\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows or handle the mismatch\n",
    "if original_df.shape[0] != triangulation_df.shape[0]:\n",
    "    print(\"Number of rows in the DataFrames do not match. Adjusting...\")\n",
    "\n",
    "    # Adjust the DataFrames to have the same number of rows\n",
    "    min_rows = min(original_df.shape[0], triangulation_df.shape[0])\n",
    "    original_df = original_df.iloc[:min_rows]\n",
    "    triangulation_df = triangulation_df.iloc[:min_rows]\n",
    "\n",
    "# Extract coordinates from DataFrames\n",
    "original_coords = original_df[['X', 'Y', 'Z']].values\n",
    "triangulation_coords = triangulation_df[['X', 'Y', 'Z']].values\n",
    "\n",
    "# Calculate differences or metrics to verify alignment\n",
    "differences = triangulation_coords - original_coords\n",
    "\n",
    "# Calculate metrics for accuracy validation\n",
    "mean_difference = differences.mean()\n",
    "rmse = ((differences ** 2).mean()) ** 0.5\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot original coordinates\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(*original_coords.T, label='Original Coordinates', c='blue')\n",
    "ax1.set_title('Original Coordinates')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot triangulation data\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(*triangulation_coords.T, label='Triangulation Data', c='orange')\n",
    "ax2.set_title('Triangulation Data')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot differences\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(*differences.T, label='Differences', c='green')\n",
    "ax3.set_title('Differences')\n",
    "ax3.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print or use the calculated metrics\n",
    "print(f\"Mean Difference: {mean_difference}\")\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942882bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Error Correction and Adjustment: Discrepancies between the virtually determined location and triangulated results \n",
    "can highlight errors or inaccuracies in the video detection or remote sensing methods. By identifying these discrepancies, \n",
    "adjustments or corrections can be made to improve the accuracy of the virtual location data.\n",
    "This process helps refine the virtual location by aligning it more closely with ground-based measurements.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e16f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Обнаружены расхождения.\n",
    "# 13. Коррекция для расхождений триангуляции.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load original coordinates from video detection\n",
    "original_df = pd.read_excel('D://Python_Project_Tracking//modified_coordinates_1.xlsx')\n",
    "\n",
    "# Load triangulation results\n",
    "triangulation_df = pd.read_excel(\"D://Python_Project_Tracking//modified_coordinates_2.xlsx\")\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows or handle the mismatch\n",
    "if original_df.shape[0] != triangulation_df.shape[0]:\n",
    "    print(\"Number of rows in the DataFrames do not match. Adjusting...\")\n",
    "\n",
    "    # Adjust the DataFrames to have the same number of rows\n",
    "    min_rows = min(original_df.shape[0], triangulation_df.shape[0])\n",
    "    original_df = original_df.iloc[:min_rows]\n",
    "    triangulation_df = triangulation_df.iloc[:min_rows]\n",
    "\n",
    "# Extract coordinates from DataFrames\n",
    "original_coords = original_df[['X', 'Y', 'Z']].values\n",
    "triangulation_coords = triangulation_df[['X', 'Y', 'Z']].values\n",
    "\n",
    "# Calculate differences or metrics to verify alignment\n",
    "differences = triangulation_coords - original_coords\n",
    "\n",
    "# Apply an adjustment factor to correct the differences\n",
    "adjustment_factor = 0.99  # Adjust this value based on the analysis\n",
    "adjusted_triangulated = triangulation_coords - (differences * adjustment_factor)\n",
    "\n",
    "# Save adjusted triangulated data to a new Excel file\n",
    "adjusted_df = pd.DataFrame(adjusted_triangulated, columns=['X', 'Y', 'Z'])\n",
    "adjusted_df.to_excel('D://Python_Project_Tracking//adjusted_triangulated_coordinates.xlsx', index=False)\n",
    "\n",
    "print(\"Adjusted triangulated coordinates saved to adjusted_triangulated_coordinates.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Validatio\n",
    "''' \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load original coordinates from video detection\n",
    "original_df = pd.read_excel('D://Python_Project_Tracking//modified_coordinates_1.xlsx')\n",
    "\n",
    "# Load triangulation results\n",
    "triangulation_df = pd.read_excel(\"D://Python_Project_Tracking//adjusted_triangulated_coordinates.xlsx\")\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows or handle the mismatch\n",
    "if original_df.shape[0] != triangulation_df.shape[0]:\n",
    "    print(\"Number of rows in the DataFrames do not match. Adjusting...\")\n",
    "\n",
    "    # Adjust the DataFrames to have the same number of rows\n",
    "    min_rows = min(original_df.shape[0], triangulation_df.shape[0])\n",
    "    original_df = original_df.iloc[:min_rows]\n",
    "    triangulation_df = triangulation_df.iloc[:min_rows]\n",
    "\n",
    "# Extract coordinates from DataFrames\n",
    "original_coords = original_df[['X', 'Y', 'Z']].values\n",
    "triangulation_coords = triangulation_df[['X', 'Y', 'Z']].values\n",
    "\n",
    "# Calculate differences or metrics to verify alignment\n",
    "differences = triangulation_coords - original_coords\n",
    "\n",
    "# Calculate metrics for accuracy validation\n",
    "mean_difference = differences.mean()\n",
    "rmse = ((differences ** 2).mean()) ** 0.5\n",
    "\n",
    "# Print or use the calculated metrics\n",
    "print(f\"Mean Difference: {mean_difference}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0550dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Accuracy Validation\n",
    "# 14. Проверка и визуализация скорректированных триангулированных координат.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load original coordinates from video detection\n",
    "original_df = pd.read_excel('D://Python_Project_Tracking//modified_coordinates_1.xlsx')\n",
    "\n",
    "# Load triangulation results\n",
    "triangulation_df = pd.read_excel(\"D://Python_Project_Tracking//adjusted_triangulated_coordinates.xlsx\")\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows or handle the mismatch\n",
    "if original_df.shape[0] != triangulation_df.shape[0]:\n",
    "    print(\"Number of rows in the DataFrames do not match. Adjusting...\")\n",
    "\n",
    "    # Adjust the DataFrames to have the same number of rows\n",
    "    min_rows = min(original_df.shape[0], triangulation_df.shape[0])\n",
    "    original_df = original_df.iloc[:min_rows]\n",
    "    triangulation_df = triangulation_df.iloc[:min_rows]\n",
    "\n",
    "# Extract coordinates from DataFrames\n",
    "original_coords = original_df[['X', 'Y', 'Z']].values\n",
    "triangulation_coords = triangulation_df[['X', 'Y', 'Z']].values\n",
    "\n",
    "# Calculate differences or metrics to verify alignment\n",
    "differences = triangulation_coords - original_coords\n",
    "\n",
    "# Calculate metrics for accuracy validation\n",
    "mean_difference = differences.mean()\n",
    "rmse = ((differences ** 2).mean()) ** 0.5\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot original coordinates\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax1.scatter(*original_coords.T, label='Original Coordinates', c='blue')\n",
    "ax1.set_title('Original Coordinates')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot triangulation data\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax2.scatter(*triangulation_coords.T, label='Triangulation Data', c='orange')\n",
    "ax2.set_title('Triangulation Data')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot differences\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "ax3.scatter(*differences.T, label='Differences', c='green')\n",
    "ax3.set_title('Differences')\n",
    "ax3.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print or use the calculated metrics\n",
    "print(f\"Mean Difference: {mean_difference}\")\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310c532",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Triangulation results visualizations\n",
    "# 15. 3D моделирование движения объекта после операции \"Коррекция для расхождений триангуляции\".\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib.widgets import Button\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "from matplotlib.widgets import Button\n",
    "import os\n",
    "\n",
    "# Load data from satellite_information.xlsx\n",
    "data = pd.read_excel('D://Python_Project_Tracking//adjusted_triangulated_coordinates.xlsx')\n",
    "output_folder = 'D://Python_Project_Tracking//Triangulation_After_modified'\n",
    "\n",
    "def save_step_image(step_num, fig):\n",
    "    folder_path = output_folder\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    plt.savefig(os.path.join(folder_path, f'step_{step_num:03d}.png'))\n",
    "\n",
    "# Extract X, Y, and Z coordinates from the loaded data\n",
    "object_positions_x = data['X'].tolist()\n",
    "object_positions_y = data['Y'].tolist()\n",
    "object_positions_z = data['Z'].tolist()\n",
    "\n",
    "# Define sensor positions within the range of -100 to 1000 for x, y, and z axes\n",
    "sensor_positions = [\n",
    "    (-10000, -10000, 0),  # Sensor 1 position (x, y, z)\n",
    "    (13000, -13000, 0),  # Sensor 2 position (x, y, z)\n",
    "    (0, 14000, 0),       # Sensor 3 position (x, y, z)\n",
    "]\n",
    "\n",
    "# Create a 3D figure\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Adding a 3D subplot\n",
    "\n",
    "# Set limits for x, y, and z axes\n",
    "ax.set_xlim(-15000, 15000)\n",
    "ax.set_ylim(-15000, 15000)\n",
    "ax.set_zlim(-15000, 15000)\n",
    "\n",
    "# Plot sensor positions in 3D\n",
    "for sensor_pos in sensor_positions:\n",
    "    ax.scatter(sensor_pos[0], sensor_pos[1], sensor_pos[2], color='red', marker='^', label='Sensor')\n",
    "\n",
    "# Label sensors in 3D\n",
    "sensor_labels = ['Sensor 1', 'Sensor 2', 'Sensor 3']\n",
    "for i, sensor_pos in enumerate(sensor_positions):\n",
    "    ax.text(sensor_pos[0], sensor_pos[1], sensor_pos[2], sensor_labels[i], color='black', fontsize=10)\n",
    "\n",
    "# Initialize variables for simulation control\n",
    "paused = False\n",
    "current_step = 0\n",
    "sensor_lines = []  # Store sensor lines\n",
    "exit_simulation = False  # Define the exit_simulation flag\n",
    "\n",
    "def toggle_pause(event):\n",
    "    global paused\n",
    "    paused = not paused\n",
    "\n",
    "    if paused:\n",
    "        button.label.set_text('Resume')\n",
    "    else:\n",
    "        button.label.set_text('Pause')\n",
    "        simulate(current_step)  # Resume simulation from the current step\n",
    "\n",
    "# Pause/Resume button\n",
    "button_ax = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "button = Button(button_ax, 'Pause')\n",
    "button.on_clicked(toggle_pause)\n",
    "\n",
    "def on_key(event):\n",
    "    global paused, exit_simulation\n",
    "    if event.key == 'q':\n",
    "        exit_simulation = True\n",
    "\n",
    "fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "def simulate(start_step=0):\n",
    "    global current_step, paused, sensor_lines, exit_simulation\n",
    "\n",
    "    for i in range(start_step, len(object_positions_x)):\n",
    "        if exit_simulation:\n",
    "            break\n",
    "\n",
    "        if not paused:\n",
    "            current_step = i\n",
    "\n",
    "            scaling_factor = 3\n",
    "            object_x = object_positions_x[i] * scaling_factor\n",
    "            object_y = object_positions_y[i] * scaling_factor\n",
    "            object_z = object_positions_z[i] * scaling_factor  # Fetch the Z-coordinate\n",
    "\n",
    "            ax.scatter(object_x, object_y, object_z, color='blue', marker='o', label='Object Position')\n",
    "\n",
    "            if i > 0:  # Connect consecutive object positions with a line\n",
    "                ax.plot([object_positions_x[i-1]*scaling_factor, object_x],\n",
    "                        [object_positions_y[i-1]*scaling_factor, object_y],\n",
    "                        [object_positions_z[i-1]*scaling_factor, object_z],\n",
    "                        color='green', linestyle='-', label='_nolegend_')\n",
    "\n",
    "            # Remove previous sensor lines\n",
    "            for line in sensor_lines:\n",
    "                line.remove()\n",
    "\n",
    "            sensor_lines = []  # Clear sensor lines list for new lines\n",
    "\n",
    "            # Draw sensor lines\n",
    "            for sensor_pos in sensor_positions:\n",
    "                sensor_line = ax.plot([object_x, sensor_pos[0]],\n",
    "                                      [object_y, sensor_pos[1]],\n",
    "                                      [object_z, sensor_pos[2]],\n",
    "                                      linestyle='--', color='green', alpha=0.5, label='_nolegend_')\n",
    "                sensor_lines.append(sensor_line[0])\n",
    "\n",
    "            plt.title(f'Object Movement: Step {i+1}')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            save_step_image(i, fig)\n",
    "            plt.pause(0.1)\n",
    "\n",
    "    if not exit_simulation:\n",
    "        plt.close(fig)  # Close the figure if simulation completes without 'q' key press\n",
    "\n",
    "# Start simulation\n",
    "simulate()\n",
    "\n",
    "# Check if the simulation is paused before displaying the plot\n",
    "if paused:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.show(block=False)  # Set block=False to keep the figure open without blocking code execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images (steps of the movment pf our object) to video \n",
    "# 16. Преобразование изображений в видео для 3D моделирования движения объекта после операции \"Коррекция для расхождений триангуляции\".\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to the directory containing images\n",
    "images_folder = 'D://Python_Project_Tracking//Output'  # Path to your image folder\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = sorted([os.path.join(images_folder, f) for f in os.listdir(images_folder) if f.endswith(('.png', '.jpg', '.jpeg', '.gif'))])\n",
    "\n",
    "# Get the first image to extract dimensions\n",
    "first_image = cv2.imread(image_files[0])\n",
    "height, width, layers = first_image.shape\n",
    "\n",
    "# Video filename and codec\n",
    "video_filename = 'D://Python_Project_Tracking//output_video.mp4'  # Path for the output video\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4\n",
    "\n",
    "# Create VideoWriter object\n",
    "video = cv2.VideoWriter(video_filename, codec, 24, (width, height))\n",
    "\n",
    "# Write images to video\n",
    "for image in image_files:\n",
    "    img = cv2.imread(image)\n",
    "    video.write(img)\n",
    "\n",
    "# Release video object\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002e9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Оценка производительности датчиков с визуализациями.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load data from adjusted_triangulated_coordinates.xlsx (simulated data)\n",
    "data = pd.read_excel('D://Python_Project_Tracking//adjusted_triangulated_coordinates.xlsx')\n",
    "\n",
    "# Extract X, Y, and Z coordinates from the loaded data\n",
    "object_positions_x = data['X'].tolist()\n",
    "object_positions_y = data['Y'].tolist()\n",
    "object_positions_z = data['Z'].tolist()\n",
    "\n",
    "# Define sensor positions within the range of -100 to 1000 for x, y, and z axes\n",
    "sensor_positions = [\n",
    "    (-10000, -10000, 0),  # Sensor 1 position (x, y, z)\n",
    "    (13000, -13000, 0),  # Sensor 2 position (x, y, z)\n",
    "    (0, 14000, 0),       # Sensor 3 position (x, y, z)\n",
    "]\n",
    "\n",
    "# Calculate differences or discrepancies\n",
    "differences = []\n",
    "for i in range(len(object_positions_x)):\n",
    "    object_pos = (object_positions_x[i], object_positions_y[i], object_positions_z[i])\n",
    "    sensor_distances = [((object_pos[0] - sensor[0])**2 + (object_pos[1] - sensor[1])**2 + (object_pos[2] - sensor[2])**2)**0.5\n",
    "                        for sensor in sensor_positions]\n",
    "    differences.append([abs(dist - min(sensor_distances)) for dist in sensor_distances])\n",
    "\n",
    "# Calculate Assessment Metrics\n",
    "mean_difference = sum(sum(step) for step in differences) / len(differences)\n",
    "std_deviation = np.std(differences)\n",
    "max_deviation = np.max(differences)\n",
    "\n",
    "# Create a DataFrame for the statistical values\n",
    "stats_data = pd.DataFrame({\n",
    "    'Metric': ['Mean Difference', 'Standard Deviation', 'Max Deviation'],\n",
    "    'Value': [mean_difference, std_deviation, max_deviation]\n",
    "})\n",
    "\n",
    "# Set the directory for saving files\n",
    "output_directory = 'D://Python_Project_Tracking//statistical_values'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Save statistical values to Excel in the specified directory\n",
    "stats_data.to_excel(os.path.join(output_directory, 'statistical_values.xlsx'), index=False)\n",
    "\n",
    "# Visualization for Mean Differences and save the figure to the specified directory\n",
    "plt.figure()\n",
    "plt.plot(range(len(differences)), [sum(step) / len(step) for step in differences], label='Mean Differences')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Mean Difference')\n",
    "plt.title('Mean Differences Over Time')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_directory, 'Mean_Difference.png'))\n",
    "\n",
    "# Visualization for Standard Deviation and Max Deviation and save the figure to the specified directory\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar('Standard Deviation', std_deviation, color='skyblue', label='Standard Deviation')\n",
    "plt.bar('Max Deviation', max_deviation, color='salmon', label='Max Deviation')\n",
    "plt.title('Comparison of Standard Deviation and Max Deviation')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_directory, 'Standard_Max_Deviation.png'))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print the calculated metrics\n",
    "print(f\"Mean Difference: {mean_difference}\")\n",
    "print(f\"Standard Deviation: {std_deviation}\")\n",
    "print(f\"Max Deviation: {max_deviation}\")\n",
    "\n",
    "print(\"Statistical values and images saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc837425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
